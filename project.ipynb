{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "id": "-nwfa76GTabK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wget"
      ],
      "metadata": {
        "id": "zmC2XdBFKUA9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install split-folders tqdm"
      ],
      "metadata": {
        "id": "ulGCLOkcwkmD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "voc 2012 dataset"
      ],
      "metadata": {
        "id": "RzcOQIkPPB9z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import wget\n",
        "import os\n",
        "import tarfile\n",
        "\n",
        "%cd \"/content/drive/MyDrive/project/voc\"\n",
        "\n",
        "wget.download('http://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar')#test set down\n",
        "\n",
        "fname = '/content/drive/MyDrive/project/voc/VOCtrainval_11-May-2012.tar'  \n",
        "ap = tarfile.open(fname)\n",
        "\n",
        "ap.extractall('/content/drive/MyDrive/project/voc/image')\n",
        " \n",
        "ap.close()\n",
        "\n",
        "os.remove('/content/drive/MyDrive/project/coco/image/annotations_trainval2017.zip')#tar file 삭제"
      ],
      "metadata": {
        "id": "airdbfwKPOkb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "import"
      ],
      "metadata": {
        "id": "T3V9t5fpRHRx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import PIL\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as f\n",
        "import torchvision.models as models\n",
        "import torch.optim as optim\n",
        "from torchvision import models\n",
        "\n",
        "import numpy as np\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "uXv5OG0SRGk1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "gpu 사용 설정"
      ],
      "metadata": {
        "id": "D8PWYalwPkpV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "id": "fluZ2vEYPmAY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "data preprocessing"
      ],
      "metadata": {
        "id": "6mSkf40OPsrc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 21\n",
        "data_root = '/content/drive/MyDrive/project/voc/image/VOCdevkit/VOC2012'"
      ],
      "metadata": {
        "id": "vyJcLN1aPuub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "voc_classes = ('background', 'aeroplane', 'bicyle', 'bird', 'boat', 'bottle',\n",
        "               'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse',\n",
        "               'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor')"
      ],
      "metadata": {
        "id": "rdTY9O94PwIy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(voc_classes)"
      ],
      "metadata": {
        "id": "0nuyhjPJPxiS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VOC2012dataset(torch.utils.data.Dataset):\n",
        "    \n",
        "    def __init__(self, num_classes, list_file, img_dir, segmentation_dir, transform=None):\n",
        "        self.num_classes = num_classes\n",
        "        self.images = open(list_file, \"rt\").read().split(\"\\n\")[:-1]\n",
        "        self.transform = transform\n",
        "        self.img_extension = \".jpg\"\n",
        "        self.segmentation_extension = \".png\"\n",
        "        self.image_root_dir = img_dir\n",
        "        self.segmentation_root_dir = segmentation_dir\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        name = self.images[index]\n",
        "        image_path = os.path.join(self.image_root_dir, name + self.img_extension)\n",
        "        segmentation_path = os.path.join(self.segmentation_root_dir, name + self.segmentation_extension)\n",
        "\n",
        "        image = self.load_image(path=image_path)\n",
        "        gt_segmentation = self.load_segmentation(path=segmentation_path)\n",
        "\n",
        "        return torch.FloatTensor(image), torch.LongTensor(gt_segmentation)\n",
        "\n",
        "    \n",
        "    def load_image(self, path=None):\n",
        "        raw_image = PIL.Image.open(path)\n",
        "        raw_image = np.transpose(raw_image.resize((224, 224)), (2,1,0))\n",
        "        imx_t = np.array(raw_image, dtype=np.float32)/255.0\n",
        "        return imx_t\n",
        "\n",
        "    \n",
        "    def load_segmentation(self, path=None):\n",
        "        raw_image = PIL.Image.open(path)\n",
        "        raw_image = raw_image.resize((224, 224))\n",
        "        imx_t = np.array(raw_image)\n",
        "        imx_t[imx_t==255] = self.num_classes-1\n",
        "        return imx_t"
      ],
      "metadata": {
        "id": "ymieki-mPx6C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "hyperparameter"
      ],
      "metadata": {
        "id": "UX0aI8JsP6oC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "num_epochs = 45\n",
        "learning_rate = 0.0003"
      ],
      "metadata": {
        "id": "JyLZsbY-P5YN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "train & validation dataset, dataloader"
      ],
      "metadata": {
        "id": "LpHpcmTfQHsi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = os.path.join(data_root, '/content/drive/MyDrive/project/voc/image/VOCdevkit/VOC2012/ImageSets/Segmentation/train.txt')\n",
        "val_path = os.path.join(data_root, '/content/drive/MyDrive/project/voc/image/VOCdevkit/VOC2012/ImageSets/Segmentation/val.txt')\n",
        "\n",
        "img_dir = os.path.join(data_root, \"JPEGImages\")\n",
        "segmentation_dir = os.path.join(data_root, \"SegmentationClass\")"
      ],
      "metadata": {
        "id": "6xdSpsdoQDCG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = VOC2012dataset(num_classes = num_classes, \n",
        "                                 list_file = train_path,\n",
        "                                 img_dir = img_dir, \n",
        "                                 segmentation_dir=segmentation_dir)\n",
        "\n",
        "val_dataset = VOC2012dataset(num_classes = num_classes, \n",
        "                               list_file=val_path,\n",
        "                               img_dir=img_dir, \n",
        "                               segmentation_dir=segmentation_dir)"
      ],
      "metadata": {
        "id": "hyYi91OoQJbu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_dataset, \n",
        "                                           batch_size = batch_size,\n",
        "                                           shuffle=True)\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, \n",
        "                                         batch_size = batch_size,\n",
        "                                         shuffle=False)"
      ],
      "metadata": {
        "id": "F03g8-niQQtt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_path = os.path.join(data_root, 'ImageSets/Segmentation/test.txt')\n",
        "\n",
        "test_dataset = VOC2012dataset(num_classes = num_classes, \n",
        "                               list_file=test_path,\n",
        "                               img_dir=img_dir, \n",
        "                               segmentation_dir=segmentation_dir)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(val_dataset, \n",
        "                                         batch_size = batch_size,\n",
        "                                         shuffle=False)"
      ],
      "metadata": {
        "id": "u9vnyJ-GWUs-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Train Dataset:')\n",
        "print('length :', len(train_dataset))\n",
        "print('Validation Dataset:')\n",
        "print('length :', len(val_dataset))"
      ],
      "metadata": {
        "id": "sCFPfDysQSVt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Test Dataset:')\n",
        "print('length :', len(test_dataset))"
      ],
      "metadata": {
        "id": "Ew8J_j_yXK4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "FCN 8s"
      ],
      "metadata": {
        "id": "hoNh40AO_8R8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FCN8s(nn.Module):\n",
        "    def __init__(self, num_classes=21):\n",
        "        super(FCN8s, self).__init__()\n",
        "        self.relu    = nn.ReLU(inplace=True)\n",
        "\n",
        "        # conv1 \n",
        "        self.conv1_1 = nn.Conv2d(3, 64, 3, padding=100)\n",
        "        self.relu1_1 = nn.ReLU(inplace=True)\n",
        "        self.conv1_2 = nn.Conv2d(64, 64, 3, padding=1)\n",
        "        self.relu1_2 = nn.ReLU(inplace=True)\n",
        "        self.pool1 = nn.MaxPool2d(2, stride=2, ceil_mode=True) \n",
        "\n",
        "        # conv2 \n",
        "        self.conv2_1 = nn.Conv2d(64, 128, 3, padding=1)\n",
        "        self.relu2_1 = nn.ReLU(inplace=True)\n",
        "        self.conv2_2 = nn.Conv2d(128, 128, 3, padding=1)\n",
        "        self.relu2_2 = nn.ReLU(inplace=True)\n",
        "        self.pool2 = nn.MaxPool2d(2, stride=2, ceil_mode=True) \n",
        "\n",
        "        # conv3\n",
        "        self.conv3_1 = nn.Conv2d(128, 256, 3, padding=1)\n",
        "        self.relu3_1 = nn.ReLU(inplace=True)\n",
        "        self.conv3_2 = nn.Conv2d(256, 256, 3, padding=1)\n",
        "        self.relu3_2 = nn.ReLU(inplace=True)\n",
        "        self.conv3_3 = nn.Conv2d(256, 256, 3, padding=1)\n",
        "        self.relu3_3 = nn.ReLU(inplace=True)\n",
        "        self.pool3 = nn.MaxPool2d(2, stride=2, ceil_mode=True) \n",
        "\n",
        "        # conv4\n",
        "        self.conv4_1 = nn.Conv2d(256, 512, 3, padding=1)\n",
        "        self.relu4_1 = nn.ReLU(inplace=True)\n",
        "        self.conv4_2 = nn.Conv2d(512, 512, 3, padding=1)\n",
        "        self.relu4_2 = nn.ReLU(inplace=True)\n",
        "        self.conv4_3 = nn.Conv2d(512, 512, 3, padding=1)\n",
        "        self.relu4_3 = nn.ReLU(inplace=True)\n",
        "        self.pool4 = nn.MaxPool2d(2, stride=2, ceil_mode=True) \n",
        "\n",
        "        # conv3\n",
        "        self.conv5_1 = nn.Conv2d(512, 512, 3, padding=1)\n",
        "        self.relu5_1 = nn.ReLU(inplace=True)\n",
        "        self.conv5_2 = nn.Conv2d(512, 512, 3, padding=1)\n",
        "        self.relu5_2 = nn.ReLU(inplace=True)\n",
        "        self.conv5_3 = nn.Conv2d(512, 512, 3, padding=1)\n",
        "        self.relu5_3 = nn.ReLU(inplace=True)\n",
        "        self.pool5 = nn.MaxPool2d(2, stride=2, ceil_mode=True) \n",
        "\n",
        "        self.score_pool3 = nn.Conv2d(256, num_classes, 1)\n",
        "        self.score_pool4 = nn.Conv2d(512, num_classes, 1)\n",
        "\n",
        "        # fc1\n",
        "        self.fc6 = nn.Conv2d(512, 4096, 7)\n",
        "        self.relu6 = nn.ReLU(inplace=True)\n",
        "        self.drop6 = nn.Dropout2d()\n",
        "\n",
        "        # fc2\n",
        "        self.fc7 = nn.Conv2d(4096, 4096, 1)\n",
        "        self.relu7 = nn.ReLU(inplace=True)\n",
        "        self.drop7 = nn.Dropout2d()\n",
        "\n",
        "        # fc3\n",
        "        self.score_fr = nn.Conv2d(4096, num_classes, kernel_size = 1)\n",
        "        self.upscore2 = nn.ConvTranspose2d(num_classes, num_classes, kernel_size = 4, stride = 2)\n",
        "        self.upscore2_pool4 = nn.ConvTranspose2d(num_classes, num_classes, kernel_size = 4, stride = 2)\n",
        "        self.upscore8 = nn.ConvTranspose2d(num_classes, num_classes, kernel_size = 16, stride = 8)\n",
        "\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                torch.nn.init.xavier_uniform_(m.weight)\n",
        "\n",
        "                if m.bias is not None:\n",
        "                    torch.nn.init.zeros_(m.bias)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = self.relu1_1(self.conv1_1(x))\n",
        "        h = self.relu1_2(self.conv1_2(h))\n",
        "        h = self.pool1(h)\n",
        "\n",
        "        h = self.relu2_1(self.conv2_1(h))\n",
        "        h = self.relu2_2(self.conv2_2(h))\n",
        "        h = self.pool2(h)\n",
        "\n",
        "        h = self.relu3_1(self.conv3_1(h))\n",
        "        h = self.relu3_2(self.conv3_2(h))\n",
        "        h = self.relu3_3(self.conv3_3(h))\n",
        "        pool3 = h = self.pool3(h)\n",
        "\n",
        "        h = self.relu4_1(self.conv4_1(h))\n",
        "        h = self.relu4_2(self.conv4_2(h))\n",
        "        h = self.relu4_3(self.conv4_3(h))\n",
        "        pool4 = h = self.pool4(h)\n",
        "\n",
        "        h = self.relu5_1(self.conv5_1(h))\n",
        "        h = self.relu5_2(self.conv5_2(h))\n",
        "        h = self.relu5_3(self.conv5_3(h))\n",
        "        h = self.pool5(h)\n",
        "\n",
        "        h = self.relu6(self.fc6(h))\n",
        "        h = self.drop6(h)\n",
        "\n",
        "        h = self.relu7(self.fc7(h))\n",
        "        h = self.drop7(h)\n",
        "\n",
        "        pool3 = self.score_pool3(pool3)\n",
        "        pool4 = self.score_pool4(pool4)\n",
        "\n",
        "        h = self.score_fr(h)\n",
        "        upscore2 = self.upscore2(h)         \n",
        "\n",
        "        dh, dw = (pool4.size()[2] - upscore2.size()[2])//2, (pool4.size()[3] - upscore2.size()[3])//2\n",
        "        upscore2_pool4 = self.upscore2_pool4(upscore2 + pool4[:, :, dh:(dh + upscore2.size()[2]), dw:(dw + upscore2.size()[3])])\n",
        "\n",
        "        dh, dw = (pool3.size()[2] - upscore2_pool4.size()[2])//2, (pool3.size()[3] - upscore2_pool4.size()[3])//2\n",
        "        upscore8 = self.upscore8(upscore2_pool4 + pool3[:, :, dh:(dh + upscore2_pool4.size()[2]), dw:(dw + upscore2_pool4.size()[3])])\n",
        "\n",
        "        dh, dw = (upscore8.size()[2] - x.size()[2])//2, (upscore8.size()[3] - x.size()[3])//2\n",
        "        return torch.sigmoid(upscore8[:, :, dh:(dh + x.size()[2]), dw:(dw + x.size()[3])])"
      ],
      "metadata": {
        "id": "Go69Zjl5_-lh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "FCN2s"
      ],
      "metadata": {
        "id": "Ur2e0IXdRBeM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FCN2s(nn.Module):\n",
        "  def __init__(self, num_classes=21):\n",
        "    super(FCN2s, self).__init__()\n",
        "    self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    #convolution1\n",
        "    self.conv1_1 = nn.Conv2d(3, 64, 3, padding=100)\n",
        "    self.relu1_1 = nn.ReLU(inplace=True)\n",
        "    self.conv1_2 = nn.Conv2d(64, 64, 3, padding=1)\n",
        "    self.relu1_2 = nn.ReLU(inplace=True)\n",
        "    self.pool1 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n",
        "\n",
        "    #convolution2\n",
        "    self.conv2_1 = nn.Conv2d(64, 128, 3, padding=1)\n",
        "    self.relu2_1 = nn.ReLU(inplace=True)\n",
        "    self.conv2_2 = nn.Conv2d(128, 128, 3, padding=1)\n",
        "    self.relu2_2 = nn.ReLU(inplace=True)\n",
        "    self.pool2 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n",
        "\n",
        "    #convolution3\n",
        "    self.conv3_1 = nn.Conv2d(128, 256, 3, padding=1)\n",
        "    self.relu3_1 = nn.ReLU(inplace=True)\n",
        "    self.conv3_2 = nn.Conv2d(256, 256, 3, padding=1)\n",
        "    self.relu3_2 = nn.ReLU(inplace=True)\n",
        "    self.conv3_3 = nn.Conv2d(256, 256, 3, padding=1)\n",
        "    self.relu3_3 = nn.ReLU(inplace=True)\n",
        "    self.pool3 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n",
        "\n",
        "    #convolution4\n",
        "    self.conv4_1 = nn.Conv2d(256, 512, 3, padding=1)\n",
        "    self.relu4_1 = nn.ReLU(inplace=True)\n",
        "    self.conv4_2 = nn.Conv2d(512, 512, 3, padding=1)\n",
        "    self.relu4_2 = nn.ReLU(inplace=True)\n",
        "    self.conv4_3 = nn.Conv2d(512, 512, 3, padding=1)\n",
        "    self.relu4_3 = nn.ReLU(inplace=True)\n",
        "    self.pool4 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n",
        "\n",
        "    #convolution5\n",
        "    self.conv5_1 = nn.Conv2d(512, 512, 3, padding=1)\n",
        "    self.relu5_1 = nn.ReLU(inplace=True)\n",
        "    self.conv5_2 = nn.Conv2d(512, 512, 3, padding=1)\n",
        "    self.relu5_2 = nn.ReLU(inplace=True)\n",
        "    self.conv5_3 = nn.Conv2d(512, 512, 3, padding=1)\n",
        "    self.relu5_3 = nn.ReLU(inplace=True)\n",
        "    self.pool5 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n",
        "\n",
        "    self.score_pool1 = nn.Conv2d(64, num_classes, 1)\n",
        "    self.score_pool2 = nn.Conv2d(128, num_classes, 1)\n",
        "    self.score_pool3 = nn.Conv2d(256, num_classes, 1)\n",
        "    self.score_pool4 = nn.Conv2d(512, num_classes, 1)\n",
        "\n",
        "    #fully convolution6\n",
        "    self.fc6 = nn.Conv2d(512, 4096, 7)\n",
        "    self.relu6 = nn.ReLU(inplace=True)\n",
        "    self.drop6 = nn.Dropout2d()\n",
        "\n",
        "    #fully convolution7\n",
        "    self.fc7 = nn.Conv2d(4096, 4096, 1)\n",
        "    self.relu7 = nn.ReLU(inplace=True)\n",
        "    self.drop7 = nn.Dropout2d()\n",
        "\n",
        "    #score\n",
        "    self.score_fr = nn.Conv2d(4096, num_classes, kernel_size=1)\n",
        "    self.upscore2_1 = nn.ConvTranspose2d(num_classes, num_classes, kernel_size=4, stride=2)\n",
        "    self.upscore2_pool4 = nn.ConvTranspose2d(num_classes, num_classes, kernel_size=4, stride=2)\n",
        "    self.upscore2_pool3 = nn.ConvTranspose2d(num_classes, num_classes, kernel_size=4, stride=2)\n",
        "    self.upscore2_pool2 = nn.ConvTranspose2d(num_classes, num_classes, kernel_size=4, stride=2)\n",
        "    self.upscore2_2 = nn.ConvTranspose2d(num_classes, num_classes, kernel_size=4, stride=2)\n",
        "\n",
        "    self._initialize_weights()\n",
        "\n",
        "  def _initialize_weights(self):\n",
        "    for m in self.modules():\n",
        "      if isinstance(m, nn.Conv2d):\n",
        "        torch.nn.init.xavier_uniform_(m.weight)\n",
        "\n",
        "        if m.bias is not None:\n",
        "          torch.nn.init.zeros_(m.bias)\n",
        "\n",
        "  def forward(self, x):\n",
        "        h = self.relu1_1(self.conv1_1(x))\n",
        "        h = self.relu1_2(self.conv1_2(h))\n",
        "        pool1 = h = self.pool1(h)\n",
        "\n",
        "        h = self.relu2_1(self.conv2_1(h))\n",
        "        h = self.relu2_2(self.conv2_2(h))\n",
        "        pool2 = h = self.pool2(h)\n",
        "\n",
        "        h = self.relu3_1(self.conv3_1(h))\n",
        "        h = self.relu3_2(self.conv3_2(h))\n",
        "        h = self.relu3_3(self.conv3_3(h))\n",
        "        pool3 = h = self.pool3(h)\n",
        "\n",
        "        h = self.relu4_1(self.conv4_1(h))\n",
        "        h = self.relu4_2(self.conv4_2(h))\n",
        "        h = self.relu4_3(self.conv4_3(h))\n",
        "        pool4 = h = self.pool4(h)\n",
        "        \n",
        "        h = self.relu5_1(self.conv5_1(h))\n",
        "        h = self.relu5_2(self.conv5_2(h))\n",
        "        h = self.relu5_3(self.conv5_3(h))\n",
        "        h = self.pool5(h)\n",
        "        \n",
        "        h = self.relu6(self.fc6(h))\n",
        "        h = self.drop6(h)\n",
        "\n",
        "        h = self.relu7(self.fc7(h))\n",
        "        h = self.drop7(h)\n",
        "        \n",
        "        pool1 = self.score_pool1(pool1)\n",
        "        pool2 = self.score_pool2(pool2)\n",
        "        pool3 = self.score_pool3(pool3)\n",
        "        pool4 = self.score_pool4(pool4)\n",
        "        \n",
        "        h = self.score_fr(h)\n",
        "        upscore2_1 = self.upscore2_1(h)         \n",
        "        \n",
        "        dh, dw = (pool4.size()[2] - upscore2_1.size()[2])//2, (pool4.size()[3] - upscore2_1.size()[3])//2\n",
        "        upscore2_pool4 = self.upscore2_pool4(upscore2_1 + pool4[:, :, dh:(dh + upscore2_1.size()[2]), dw:(dw + upscore2_1.size()[3])])\n",
        "        \n",
        "        dh, dw = (pool3.size()[2] - upscore2_pool4.size()[2])//2, (pool3.size()[3] - upscore2_pool4.size()[3])//2\n",
        "        upscore2_pool3 = self.upscore2_pool3(upscore2_pool4 + pool3[:, :, dh:(dh + upscore2_pool4.size()[2]), dw:(dw + upscore2_pool4.size()[3])])\n",
        "\n",
        "        dh, dw = (pool2.size()[2] - upscore2_pool3.size()[2])//2, (pool2.size()[3] - upscore2_pool3.size()[3])//2\n",
        "        upscore2_pool2 = self.upscore2_pool2(upscore2_pool3 + pool2[:, :, dh:(dh + upscore2_pool3.size()[2]), dw:(dw + upscore2_pool3.size()[3])])\n",
        "\n",
        "        dh, dw = (pool1.size()[2] - upscore2_pool2.size()[2])//2, (pool1.size()[3] - upscore2_pool2.size()[3])//2\n",
        "        upscore2_2 = self.upscore2_2(upscore2_pool2 + pool1[:, :, dh:(dh + upscore2_pool2.size()[2]), dw:(dw + upscore2_pool2.size()[3])])\n",
        "\n",
        "        dh, dw = (upscore2_2.size()[2] - x.size()[2])//2, (upscore2_2.size()[3] - x.size()[3])//2\n",
        "        return torch.sigmoid(upscore2_2[:, :, dh:(dh + x.size()[2]), dw:(dw + x.size()[3])])"
      ],
      "metadata": {
        "id": "cSF47jKHRE9l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TransConv"
      ],
      "metadata": {
        "id": "RZmuaIg0RTVX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransConv(nn.Module):\n",
        "    def __init__(self, num_classes=21):\n",
        "        super(TransConv, self).__init__()\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        def Conv(in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n",
        "\n",
        "            return nn.Sequential(\n",
        "                nn.Conv2d(in_channels=in_channels, \n",
        "                          out_channels=out_channels,\n",
        "                          kernel_size=kernel_size,\n",
        "                          stride=stride,\n",
        "                          padding=padding),\n",
        "                nn.BatchNorm2d(out_channels),\n",
        "                nn.ReLU())\n",
        "\n",
        "        def TConv(in_channels, out_channels, kernel_size=4, stride=2, padding=1):\n",
        "\n",
        "            return nn.Sequential(\n",
        "                nn.ConvTranspose2d(in_channels=in_channels, \n",
        "                                   out_channels=out_channels,\n",
        "                                   kernel_size=kernel_size, \n",
        "                                   stride=stride,\n",
        "                                   padding=padding),\n",
        "                nn.BatchNorm2d(out_channels),\n",
        "                nn.ReLU())        \n",
        "\n",
        "        #convolution1\n",
        "        self.conv1_1 = Conv(3, 64, 3, 1, 1)\n",
        "        self.conv1_2 = Conv(64, 64, 3, 1, 1)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2, ceil_mode=True, return_indices=True) # 1/2\n",
        "\n",
        "        #convolution2 \n",
        "        self.conv2_1 = Conv(64, 128, 3, 1, 1)\n",
        "        self.conv2_2 = Conv(128, 128, 3, 1, 1)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2, ceil_mode=True, return_indices=True) # 1/4\n",
        "\n",
        "        #convolution3\n",
        "        self.conv3_1 = Conv(128, 256, 3, 1, 1)\n",
        "        self.conv3_2 = Conv(256, 256, 3, 1, 1)\n",
        "        self.conv3_3 = Conv(256, 256, 3, 1, 1)        \n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2, ceil_mode=True, return_indices=True) # 1/8\n",
        "\n",
        "        #convolution4\n",
        "        self.conv4_1 = Conv(256, 512, 3, 1, 1)\n",
        "        self.conv4_2 = Conv(512, 512, 3, 1, 1)\n",
        "        self.conv4_3 = Conv(512, 512, 3, 1, 1)        \n",
        "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2, ceil_mode=True, return_indices=True) # 1/16\n",
        "\n",
        "        #convolution5\n",
        "        self.conv5_1 = Conv(512, 512, 3, 1, 1)\n",
        "        self.conv5_2 = Conv(512, 512, 3, 1, 1)\n",
        "        self.conv5_3 = Conv(512, 512, 3, 1, 1)\n",
        "        self.pool5 = nn.MaxPool2d(kernel_size=2, stride=2, ceil_mode=True, return_indices=True)\n",
        "\n",
        "        #fully convolution6\n",
        "        self.fc6 = Conv(512, 4096, 7, 1, 0)\n",
        "        self.drop6 = nn.Dropout2d(0.5)\n",
        "\n",
        "        #fully convolution7\n",
        "        self.fc7 = Conv(4096, 4096, 1, 1, 0)\n",
        "        self.drop7 = nn.Dropout2d(0.5)\n",
        "\n",
        "        #transpose convolution6\n",
        "        self.fc6_tconv = TConv(4096, 512, 7, 1, 0)\n",
        "\n",
        "        #transpose convolution5\n",
        "        self.unpool5 = nn.MaxUnpool2d(2, stride=2) #7*7 -> 14*14\n",
        "        self.tconv5_1 = TConv(512, 512, 3, 1, 1)\n",
        "        self.tconv5_2 = TConv(512, 512, 3, 1, 1)\n",
        "        self.tconv5_3 = TConv(512, 512, 3, 1, 1)\n",
        "\n",
        "        #transpose convolution4\n",
        "        self.unpool4 = nn.MaxUnpool2d(2, stride=2) #14*14 -> 28*28\n",
        "        self.tconv4_1 = TConv(512, 512, 3, 1, 1)\n",
        "        self.tconv4_2 = TConv(512, 512, 3, 1, 1)\n",
        "        self.tconv4_3 = TConv(512, 256, 3, 1, 1)\n",
        "\n",
        "        #transpose convolution3\n",
        "        self.unpool3 = nn.MaxUnpool2d(2, stride=2) #28*28 -> 56*56\n",
        "        self.tconv3_1 = TConv(256, 256, 3, 1, 1)\n",
        "        self.tconv3_2 = TConv(256, 256, 3, 1, 1)\n",
        "        self.tconv3_3 = TConv(256, 128, 3, 1, 1)\n",
        "\n",
        "        # Score\n",
        "        self.upscore8 = TConv(128, num_classes, 8, 4, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        h = self.conv1_1(x) #kernel_size=3, stride=1, padding=1 -> 224*224\n",
        "        h = self.conv1_2(h) #kernel_size=3, stride=1, padding=1 -> 224*224\n",
        "        h, pool1_indices = self.pool1(h) #kernel_size=2, stride=2, padding=0 -> 112*112\n",
        "\n",
        "        h = self.conv2_1(h) #kernel_size=3, stride=1, padding=1 -> 112*112\n",
        "        h = self.conv2_2(h) #kernel_size=3, stride=1, padding=1 -> 112*112\n",
        "        h, pool2_indices = self.pool2(h) #kernel_size=2, stride=2, padding=0 -> 56*56\n",
        "\n",
        "        h = self.conv3_1(h) #kernel_size=3, stride=1, padding=1 -> 56*56\n",
        "        h = self.conv3_2(h) #kernel_size=3, stride=1, padding=1 -> 56*56\n",
        "        h = self.conv3_3(h) #kernel_size=3, stride=1, padding=1 -> 56*56   \n",
        "        h, pool3_indices = self.pool3(h) #kernel_size=2, stride=2, padding=0 -> 28*28\n",
        "\n",
        "        h = self.conv4_1(h) #kernel_size=3, stride=1, padding=1 -> 28*28\n",
        "        h = self.conv4_2(h) #kernel_size=3, stride=1, padding=1 -> 28*28\n",
        "        h = self.conv4_3(h) #kernel_size=3, stride=1, padding=1 -> 28*28\n",
        "        h, pool4_indices = self.pool4(h) #kernel_size=2, stride=2, padding=0 -> 14*14\n",
        "\n",
        "        h = self.conv5_1(h) #kernel_size=3, stride=1, padding=1 -> 14*14\n",
        "        h = self.conv5_2(h) #kernel_size=3, stride=1, padding=1 -> 14*14\n",
        "        h = self.conv5_3(h) #kernel_size=3, stride=1, padding=1 -> 14*14     \n",
        "        h, pool5_indices = self.pool5(h) #kernel_size=2, stride=2, padding=0 -> 7*7\n",
        "\n",
        "        h = self.fc6(h)\n",
        "        h = self.drop6(h)\n",
        "\n",
        "        h = self.fc7(h)\n",
        "        h = self.drop7(h)\n",
        "\n",
        "        h = self.fc6_tconv(h)\n",
        "\n",
        "        h = self.unpool5(h, pool5_indices) #7*7 -> 14*14\n",
        "        h = self.tconv5_1(h) #14*14 -> 28*28\n",
        "        h = self.tconv5_2(h)\n",
        "        h = self.tconv5_3(h)\n",
        "\n",
        "        h = self.unpool4(h, pool4_indices) #14*14\n",
        "        h = self.tconv4_1(h) #28*28\n",
        "        h = self.tconv4_2(h)\n",
        "        h = self.tconv4_3(h)\n",
        "\n",
        "        h = self.unpool3(h, pool3_indices) #28*28\n",
        "        h = self.tconv3_1(h) #56*56\n",
        "        h = self.tconv3_2(h)\n",
        "        h = self.tconv3_3(h)\n",
        "\n",
        "        h = self.upscore8(h)           \n",
        "        return h"
      ],
      "metadata": {
        "id": "7hxrk34RRU_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "loss function, optimizer"
      ],
      "metadata": {
        "id": "JW6Ar8_GQfbN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def criterion(input, target, weight=None, size_average=True):\n",
        "    n, c, h, w = input.size()\n",
        "    nt, ht, wt = target.size()\n",
        "\n",
        "    if h != ht and w != wt:\n",
        "        input = F.interpolate(input, size=(ht, wt), mode=\"bilinear\", align_corners=True)\n",
        "\n",
        "    input = input.transpose(1, 2).transpose(2, 3).contiguous().view(-1, c)\n",
        "    target = torch.cuda.LongTensor(target.view(-1))\n",
        "\n",
        "    loss = F.cross_entropy(\n",
        "        input, target, weight=weight, size_average=size_average, ignore_index=250\n",
        "    )\n",
        "    return loss"
      ],
      "metadata": {
        "id": "qi9oeAO3Q66o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "model save"
      ],
      "metadata": {
        "id": "CfVtR4N7SGm_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_func(model, saved_dir, file_name):\n",
        "    check_point = {\n",
        "        'net': model.state_dict()\n",
        "    }\n",
        "    output_path = os.path.join(saved_dir, file_name)\n",
        "    torch.save(model, output_path)"
      ],
      "metadata": {
        "id": "OGWIKuPcXosA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "fcn 8s"
      ],
      "metadata": {
        "id": "nrN-l8lVAL2a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1007) \n",
        "\n",
        "fcn = FCN8s(num_classes=21)\n",
        "fcn = fcn.to(device)\n",
        "optimizer = torch.optim.SGD(params = fcn.parameters(), lr = learning_rate, weight_decay=1e-6)   \n",
        "\n",
        "saved_fcn = '/content/drive/MyDrive/project/model/FCN8s'"
      ],
      "metadata": {
        "id": "wEA0BxqKAMr6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "fcn2s"
      ],
      "metadata": {
        "id": "h9Dpc_AnYMEJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1007) \n",
        "\n",
        "fcn = FCN2s(num_classes=21)\n",
        "fcn = fcn.to(device)\n",
        "optimizer = torch.optim.SGD(params = fcn.parameters(), lr = learning_rate, weight_decay=1e-6)   \n",
        "\n",
        "saved_fcn = '/content/drive/MyDrive/project/model/FCN2s'"
      ],
      "metadata": {
        "id": "vxttirZeYOp1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "transconv"
      ],
      "metadata": {
        "id": "BqhLSrakYQCF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1007) \n",
        "\n",
        "tc = TransConv(num_classes=21)\n",
        "tc = tc.to(device)\n",
        "optimizer = torch.optim.SGD(params = tc.parameters(), lr = learning_rate, weight_decay=1e-6)   \n",
        "\n",
        "saved_tconv = '/content/drive/MyDrive/project/model/TransConv'"
      ],
      "metadata": {
        "id": "827KOQpvYQ99"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "train & validation function"
      ],
      "metadata": {
        "id": "W_x33uO9RoG3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(num_epochs, model, data_loader, criterion, optimizer, saved_dir, file_name, device):\n",
        "    print('Start train')\n",
        "    best_loss = 9999999\n",
        "    for epoch in range(num_epochs):\n",
        "        for step, (image, segmentation) in enumerate(data_loader):\n",
        "            image = image.type(torch.float32)\n",
        "            segmentation = segmentation.type(torch.long)\n",
        "            image, segmentation = image.to(device), segmentation.to(device)\n",
        "            \n",
        "            outputs = model(image) \n",
        "            loss = criterion(outputs, segmentation)\n",
        "            \n",
        "            optimizer.zero_grad()          \n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            if (step + 1) % 25 == 0:\n",
        "                print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(\n",
        "                    epoch+1, num_epochs, step+1, len(train_loader), loss.item()))\n",
        "                \n",
        "        if (epoch + 1) % 1 == 0:\n",
        "            avrg_loss = validation(epoch + 1, model, val_loader, criterion, device)\n",
        "            if avrg_loss < best_loss:\n",
        "                print('Best performance at epoch: {}'.format(epoch + 1))\n",
        "                print('Save model in', saved_dir)\n",
        "                best_loss = avrg_loss\n",
        "                save_func(model, saved_dir, file_name)"
      ],
      "metadata": {
        "id": "Zfv3ikrRRqwG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validation(epoch, model, data_loader, criterion, device):\n",
        "    print('Start validation #{}'.format(epoch))\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        total_loss = 0\n",
        "        cnt = 0\n",
        "        correct = 0\n",
        "        \n",
        "        for step, (image, segmentation) in enumerate(data_loader):\n",
        "            image = image.type(torch.float32)\n",
        "            segmentation = segmentation.type(torch.long)\n",
        "            image, segmentation = image.to(device), segmentation.to(device)\n",
        "\n",
        "            outputs = model(image)\n",
        "            prediction = torch.argmax(outputs, 1)\n",
        "            loss = criterion(outputs, segmentation)\n",
        "\n",
        "            correct += prediction.eq(segmentation).sum().item()\n",
        "            total_loss += loss\n",
        "            cnt += 1\n",
        "\n",
        "        avrg_loss = total_loss / cnt\n",
        "        accuracy = correct / cnt\n",
        "        print('Validation #{}  Average Loss: {:.4f} Accuracy : {:.4f}'.format(epoch, avrg_loss, accuracy))\n",
        "   \n",
        "    model.train()\n",
        "    return avrg_loss"
      ],
      "metadata": {
        "id": "0tjrFAb5RsK2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "modle train - fcn 8s"
      ],
      "metadata": {
        "id": "hmi2jIDbAUpM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train(num_epochs, fcn, train_loader, criterion, optimizer, saved_fcn, 'FCN8s_model.pt', device)"
      ],
      "metadata": {
        "id": "ClbFESVXAYTG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "model train - fcn 2s"
      ],
      "metadata": {
        "id": "3aDPYaZDRukG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train(num_epochs, fcn, train_loader, criterion, optimizer, saved_fcn, 'FCN2s_model.pt', device)"
      ],
      "metadata": {
        "id": "aOqbpAq4RxYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "model train - transconv"
      ],
      "metadata": {
        "id": "-Oy04tXzYXsL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train(num_epochs, tc, train_loader, criterion, optimizer, saved_tconv, 'TransConv_model.pt', device)"
      ],
      "metadata": {
        "id": "O0UKnSvTYa5s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "load train model - fcn 2s"
      ],
      "metadata": {
        "id": "aEoX8uTcY6e9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fcn = torch.load(os.path.join(saved_fcn, 'FCN2s_model.pt'))"
      ],
      "metadata": {
        "id": "TYhLf-vUY8nr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "load train model - transconv"
      ],
      "metadata": {
        "id": "G548WFOVZDiH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fcn = torch.load(os.path.join(saved_tconv, 'TransConv_model.pt'))"
      ],
      "metadata": {
        "id": "brBfWFCEZGLi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}